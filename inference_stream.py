import os
import sys
import wave
import librosa
import asyncio
import uvicorn
import numpy as np
from io import BytesIO
import soundfile as sf
import warnings 
from pydantic import BaseModel
from typing import AsyncGenerator, Tuple
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

sys.path.append("/root/chat2video/chat2audio/")
sys.path.append("/root/chat2video/sync-gaussian-talker/")
from app_stream import llm_to_tts_stream_all_head as llm_to_tts_stream
from render_transfer import main as audio2video



app = FastAPI()

async def process_tts_stream(
    tts_stream: AsyncGenerator[bytes, None],
    media_type: str = "wav",
    target_sr: int = 16000,
    min_chunk_size: int = 1024  # æ–°å¢æœ€å°å—å¤§å°å‚æ•°
) -> AsyncGenerator[Tuple[np.ndarray, int], None]:
    buffer = BytesIO()
    header_received = False
    pending_data = b""
    
    async for chunk in tts_stream:
        if not chunk:
            continue
            
        # ç´¯ç§¯æ•°æ®ç›´åˆ°è¾¾åˆ°æœ€å°å¤„ç†å¤§å°
        pending_data += chunk
        
        # åªæœ‰å½“æ•°æ®è¶³å¤Ÿæ—¶æ‰å¤„ç†
        if len(pending_data) < min_chunk_size and not header_received:
            continue
            
        buffer.write(pending_data)
        pending_data = b""
        
        # WAVå¤´ç‰¹æ®Šå¤„ç†
        if media_type == "wav" and not header_received:
            if buffer.getbuffer().nbytes < 44:
                continue
            header_received = True
        
        # å°è¯•è§£æéŸ³é¢‘
        buffer.seek(0)
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                audio_data, sr = sf.read(buffer)
                
                if len(audio_data) > 0:
                    # å•å£°é“å¤„ç†
                    if audio_data.ndim > 1:
                        audio_data = np.mean(audio_data, axis=1)
                    
                    # é‡é‡‡æ ·
                    if sr != target_sr:
                        audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=target_sr)
                    
                    print(f"âœ… äº§ç”ŸéŸ³é¢‘å—: {audio_data.shape} samples @ {target_sr}Hz")
                    yield audio_data, target_sr
                    
                    # é‡ç½®ç¼“å†²åŒºä½†ä¿ç•™æœªæ¶ˆè´¹æ•°æ®
                    remaining = buffer.getvalue()[buffer.tell():]
                    buffer = BytesIO()
                    buffer.write(remaining)
                    
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘è§£ææš‚ç¼“: {str(e)}")
        finally:
            buffer.seek(0, 2)
        
        await asyncio.sleep(0)


def save_bytes_stream_as_wav(byte_stream, output_path, sample_rate=32000):
    num_channels = 1
    sample_width = 2
    audio_array = np.frombuffer(byte_stream, dtype=np.int16)

    with wave.open(output_path, 'wb') as wf:
        wf.setnchannels(num_channels)
        wf.setsampwidth(sample_width)
        wf.setframerate(sample_rate)
        wf.writeframes(audio_array.tobytes())


class TTSRequest(BaseModel):
    input: str
    speaker: str = "Firefly"
    model_id : str = "Chinese1"
    prompt : str = None

@app.post("/chat2video")
async def api_llm_tts_stream(request: TTSRequest):
    tts_stream = llm_to_tts_stream(request.input, request.speaker, request.prompt, media_type="wav")
    index = 0
    video_stream = None
    async for raw_chunk in tts_stream:
        print(f"ğŸ”¥ æ”¶åˆ°åŸå§‹å—: {len(raw_chunk)} bytes")
        save_bytes_stream_as_wav(raw_chunk, f"/root/autodl-tmp/GaussianTalker/{index}.wav")
        # å¤„ç†ä¸ºéŸ³é¢‘å¸§
        async for audio_chunk, sr in process_tts_stream(
            mock_stream([raw_chunk]),  # å°†å•å—åŒ…è£…ä¸ºç”Ÿæˆå™¨
            min_chunk_size=0  # ç¦ç”¨æœ€å°å—æ£€æŸ¥
        ):
            print(f"ğŸµ å¤„ç†åçš„éŸ³é¢‘: {audio_chunk.shape}")
            from model_params import model_params
            video_stream = audio2video(['--model_path', model_params[request.model_id]['model_path'],
                                        '--source_path', model_params[request.model_id]['source_path'],
                                        '--batch', '16'], audio_chunk)
    return StreamingResponse(video_stream)

async def mock_stream(chunks):
    """å°†å•ä¸ªå—åŒ…è£…ä¸ºå¼‚æ­¥ç”Ÿæˆå™¨"""
    for chunk in chunks:
        yield chunk
  

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)